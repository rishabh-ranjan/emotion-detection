{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch import tensor\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from skimage.filters import gabor\n",
    "from skimage.feature import hog\n",
    "#import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.metrics import r2_score, precision_score, recall_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceDataset(Dataset):\n",
    "    def __init__(self, index_file):\n",
    "        self.df = pd.read_csv(open(index_file))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        Y = tensor(self.df.iloc[i][0])\n",
    "        X = tensor(self.df.iloc[i][1:])\n",
    "        return (X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = FaceDataset('play.csv')\n",
    "batch_size = 32\n",
    "train_data_loader = DataLoader(train_data, batch_size, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(2304, 100)\n",
    "        self.fc2 = nn.Linear(100, 7)\n",
    "        self.output = nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 2304)\n",
    "        tmp = []\n",
    "        for i in range(x.shape[0]):\n",
    "            image = x[i]\n",
    "            gabor_real, gabor_imag = gabor(image.reshape(48, 48), frequency=1.0)\n",
    "            gabor_real = tensor(gabor_real.ravel())\n",
    "            gabor_imag = tensor(gabor_imag.ravel())\n",
    "            hog_ = tensor(hog(image.reshape(48, 48)))\n",
    "            tmp.append(hog_)\n",
    "            #tmp.append(torch.cat((image, tensor(gabor_real.ravel()), tensor(gabor_imag.ravel()))))\n",
    "        f0 = torch.stack(tmp)\n",
    "        f1 = F.relu(self.fc1(x))\n",
    "        f2 = F.relu(self.fc2(f1))\n",
    "        return self.output(f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "NNet(\n",
      "  (fc1): Linear(in_features=2304, out_features=100, bias=True)\n",
      "  (fc2): Linear(in_features=100, out_features=7, bias=True)\n",
      "  (output): Softmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "#torch.cuda.set_device(0)\n",
    "\n",
    "net = NNet()\n",
    "net = net.to(device)\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-4)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After epoch 1, mini-batch 20, loss: 38.77716827392578\n",
      "After epoch 2, mini-batch 20, loss: 37.94069194793701\n",
      "After epoch 3, mini-batch 20, loss: 37.35272550582886\n",
      "After epoch 4, mini-batch 20, loss: 36.86849617958069\n",
      "After epoch 5, mini-batch 20, loss: 36.28807735443115\n",
      "After epoch 6, mini-batch 20, loss: 35.91375195980072\n",
      "After epoch 7, mini-batch 20, loss: 35.78340291976929\n",
      "After epoch 8, mini-batch 20, loss: 35.302658796310425\n",
      "After epoch 9, mini-batch 20, loss: 35.15214133262634\n",
      "After epoch 10, mini-batch 20, loss: 34.691609144210815\n"
     ]
    }
   ],
   "source": [
    "total_loss = 0\n",
    "for epoch in range(10):\n",
    "    for i, data in enumerate(train_data_loader, 0):\n",
    "        images, classes = data\n",
    "        images, classes = images.to(device).float(), classes.to(device).long()\n",
    "        #images, classes = images.float(), classes.long()\n",
    "        optimizer.zero_grad()\n",
    "        output = net(images)\n",
    "        #print(output)\n",
    "        \n",
    "        loss = loss_function(output, classes)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item() \n",
    "        if(i % 20 == 19):\n",
    "            print(\"After epoch {}, mini-batch {}, loss: {}\".format(epoch + 1, i + 1, total_loss))\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            total_loss = 0\n",
    "    total_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = FaceDataset('public_test.csv')\n",
    "batch_size = 32\n",
    "test_data_loader = DataLoader(train_data, batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22281345674057343\n",
      "[[ 80   0  98 290 167 131 126]\n",
      " [  7   0  16  32  10  18  15]\n",
      " [ 38   0 117 251 148 218 147]\n",
      " [115   0 105 871 144 175 211]\n",
      " [ 82   0 138 312 241 122 202]\n",
      " [ 26   0  95 139  55 296 106]\n",
      " [ 31   0 105 370 160 142 306]]\n"
     ]
    }
   ],
   "source": [
    "actual, prediction = [], []\n",
    "for i, data in enumerate(test_data_loader, 0):\n",
    "    images, classes = data\n",
    "    #images, classes = images.to(device).float(), classes.to(device).long()\n",
    "    images, classes = images.float(), classes.long()\n",
    "    actual.extend(classes.squeeze().tolist())\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    output = net(images)\n",
    "    \n",
    "    prediction.extend(torch.argmax(output, dim=1).squeeze().tolist())\n",
    "    #print(output)\n",
    "print(f1_score(actual, prediction, average='macro'))\n",
    "print(confusion_matrix(actual, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 892   98  919 1621 1097  717 1114]\n",
      "[ 379    0  674 2265  925 1102 1113]\n"
     ]
    }
   ],
   "source": [
    "print(np.bincount(np.array(actual)))\n",
    "print(np.bincount(np.array(prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
