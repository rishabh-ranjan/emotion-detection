{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch import tensor\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from skimage.filters import gabor\n",
    "from skimage.feature import hog\n",
    "#import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.metrics import r2_score, precision_score, recall_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceDataset(Dataset):\n",
    "    def __init__(self, index_file):\n",
    "        self.df = pd.read_csv(open(index_file))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        Y = tensor(self.df.iloc[i][0])\n",
    "        X = tensor(self.df.iloc[i][1:])\n",
    "        return (X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = FaceDataset('train.csv')\n",
    "batch_size = 32\n",
    "train_data_loader = DataLoader(train_data, batch_size, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(2304, 100)\n",
    "        self.fc2 = nn.Linear(100, 7)\n",
    "        self.output = nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 2304)\n",
    "        tmp = []\n",
    "        for i in range(x.shape[0]):\n",
    "            image = x[i]\n",
    "            image_np = image.detach().cpu().numpy().reshape(48, 48)\n",
    "            gabor_real, gabor_imag = gabor(image_np, frequency=1.0)\n",
    "            gabor_real = tensor(gabor_real.ravel())\n",
    "            gabor_imag = tensor(gabor_imag.ravel())\n",
    "            hog_ = tensor(hog(image_np))\n",
    "            tmp.append(hog_)\n",
    "            #tmp.append(torch.cat((image, tensor(gabor_real.ravel()), tensor(gabor_imag.ravel()))))\n",
    "        f0 = torch.stack(tmp)\n",
    "        f1 = F.relu(self.fc1(x))\n",
    "        f2 = F.relu(self.fc2(f1))\n",
    "        return self.output(f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "NNet(\n",
      "  (fc1): Linear(in_features=2304, out_features=100, bias=True)\n",
      "  (fc2): Linear(in_features=100, out_features=7, bias=True)\n",
      "  (output): Softmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "#torch.cuda.set_device(0)\n",
    "\n",
    "net = NNet()\n",
    "net = net.to(device)\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-4)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After epoch 1, mini-batch 20, loss: 38.86219024658203\n",
      "After epoch 1, mini-batch 40, loss: 38.618561148643494\n",
      "After epoch 1, mini-batch 60, loss: 38.55501437187195\n",
      "After epoch 1, mini-batch 80, loss: 38.407631635665894\n",
      "After epoch 1, mini-batch 100, loss: 37.9566193819046\n",
      "After epoch 1, mini-batch 120, loss: 37.63605093955994\n",
      "After epoch 1, mini-batch 140, loss: 37.671406984329224\n",
      "After epoch 1, mini-batch 160, loss: 37.81190752983093\n",
      "After epoch 1, mini-batch 180, loss: 37.273921489715576\n",
      "After epoch 1, mini-batch 200, loss: 37.80914914608002\n",
      "After epoch 1, mini-batch 220, loss: 37.18520724773407\n",
      "After epoch 1, mini-batch 240, loss: 37.11443817615509\n",
      "After epoch 1, mini-batch 260, loss: 37.45066154003143\n",
      "After epoch 1, mini-batch 280, loss: 37.052218437194824\n",
      "After epoch 1, mini-batch 300, loss: 36.796424984931946\n",
      "After epoch 1, mini-batch 320, loss: 36.7461941242218\n",
      "After epoch 1, mini-batch 340, loss: 37.00622892379761\n",
      "After epoch 1, mini-batch 360, loss: 36.88809251785278\n",
      "After epoch 1, mini-batch 380, loss: 36.92668533325195\n",
      "After epoch 1, mini-batch 400, loss: 36.79603314399719\n",
      "After epoch 1, mini-batch 420, loss: 36.57340395450592\n",
      "After epoch 1, mini-batch 440, loss: 36.471906304359436\n",
      "After epoch 1, mini-batch 460, loss: 36.5103862285614\n",
      "After epoch 1, mini-batch 480, loss: 36.569233417510986\n",
      "After epoch 1, mini-batch 500, loss: 36.356032967567444\n",
      "After epoch 1, mini-batch 520, loss: 36.765918135643005\n",
      "After epoch 1, mini-batch 540, loss: 36.27408730983734\n",
      "After epoch 1, mini-batch 560, loss: 36.51288139820099\n",
      "After epoch 1, mini-batch 580, loss: 35.99199664592743\n",
      "After epoch 1, mini-batch 600, loss: 36.404701352119446\n",
      "After epoch 2, mini-batch 20, loss: 36.38920319080353\n",
      "After epoch 2, mini-batch 40, loss: 36.78245460987091\n",
      "After epoch 2, mini-batch 60, loss: 35.98991358280182\n",
      "After epoch 2, mini-batch 80, loss: 35.86228156089783\n",
      "After epoch 2, mini-batch 100, loss: 36.06169414520264\n",
      "After epoch 2, mini-batch 120, loss: 36.03790843486786\n",
      "After epoch 2, mini-batch 140, loss: 36.17154145240784\n",
      "After epoch 2, mini-batch 160, loss: 35.523417234420776\n",
      "After epoch 2, mini-batch 180, loss: 35.70053780078888\n",
      "After epoch 2, mini-batch 200, loss: 36.36754012107849\n",
      "After epoch 2, mini-batch 220, loss: 36.23478364944458\n",
      "After epoch 2, mini-batch 240, loss: 35.692482471466064\n",
      "After epoch 2, mini-batch 260, loss: 35.43749487400055\n",
      "After epoch 2, mini-batch 280, loss: 35.71382236480713\n",
      "After epoch 2, mini-batch 300, loss: 35.993786096572876\n",
      "After epoch 2, mini-batch 320, loss: 35.694663286209106\n",
      "After epoch 2, mini-batch 340, loss: 35.47115445137024\n",
      "After epoch 2, mini-batch 360, loss: 35.8912273645401\n",
      "After epoch 2, mini-batch 380, loss: 35.80119526386261\n",
      "After epoch 2, mini-batch 400, loss: 36.10602021217346\n",
      "After epoch 2, mini-batch 420, loss: 35.822179317474365\n",
      "After epoch 2, mini-batch 440, loss: 35.89697504043579\n",
      "After epoch 2, mini-batch 460, loss: 35.474671483039856\n",
      "After epoch 2, mini-batch 480, loss: 35.75455951690674\n",
      "After epoch 2, mini-batch 500, loss: 35.84763300418854\n",
      "After epoch 2, mini-batch 520, loss: 35.85126805305481\n",
      "After epoch 2, mini-batch 540, loss: 35.5389586687088\n",
      "After epoch 2, mini-batch 560, loss: 35.65690886974335\n",
      "After epoch 2, mini-batch 580, loss: 36.17068362236023\n",
      "After epoch 2, mini-batch 600, loss: 35.921321749687195\n",
      "After epoch 3, mini-batch 20, loss: 35.47126054763794\n",
      "After epoch 3, mini-batch 40, loss: 35.398807406425476\n",
      "After epoch 3, mini-batch 60, loss: 35.223259925842285\n",
      "After epoch 3, mini-batch 80, loss: 35.90694797039032\n",
      "After epoch 3, mini-batch 100, loss: 35.3810396194458\n",
      "After epoch 3, mini-batch 120, loss: 35.28223943710327\n",
      "After epoch 3, mini-batch 140, loss: 35.546624541282654\n",
      "After epoch 3, mini-batch 160, loss: 35.653868198394775\n",
      "After epoch 3, mini-batch 180, loss: 35.61754262447357\n",
      "After epoch 3, mini-batch 200, loss: 35.26637518405914\n",
      "After epoch 3, mini-batch 220, loss: 35.80311167240143\n",
      "After epoch 3, mini-batch 240, loss: 35.18613338470459\n",
      "After epoch 3, mini-batch 260, loss: 35.65776741504669\n",
      "After epoch 3, mini-batch 280, loss: 35.473219990730286\n",
      "After epoch 3, mini-batch 300, loss: 35.28669345378876\n",
      "After epoch 3, mini-batch 320, loss: 35.15331530570984\n",
      "After epoch 3, mini-batch 340, loss: 35.43492090702057\n",
      "After epoch 3, mini-batch 360, loss: 35.5369998216629\n",
      "After epoch 3, mini-batch 380, loss: 35.171934366226196\n",
      "After epoch 3, mini-batch 400, loss: 35.310887575149536\n",
      "After epoch 3, mini-batch 420, loss: 34.98062241077423\n",
      "After epoch 3, mini-batch 440, loss: 35.173354625701904\n",
      "After epoch 3, mini-batch 460, loss: 35.31171715259552\n",
      "After epoch 3, mini-batch 480, loss: 35.72536897659302\n",
      "After epoch 3, mini-batch 500, loss: 35.742170453071594\n",
      "After epoch 3, mini-batch 520, loss: 35.08548438549042\n",
      "After epoch 3, mini-batch 540, loss: 35.659003257751465\n",
      "After epoch 3, mini-batch 560, loss: 35.71298563480377\n",
      "After epoch 3, mini-batch 580, loss: 35.837658166885376\n",
      "After epoch 3, mini-batch 600, loss: 34.894755601882935\n",
      "After epoch 4, mini-batch 20, loss: 35.491697549819946\n",
      "After epoch 4, mini-batch 40, loss: 35.278440713882446\n",
      "After epoch 4, mini-batch 60, loss: 35.158655285835266\n",
      "After epoch 4, mini-batch 80, loss: 35.74718463420868\n",
      "After epoch 4, mini-batch 100, loss: 35.035810112953186\n",
      "After epoch 4, mini-batch 120, loss: 35.02618062496185\n",
      "After epoch 4, mini-batch 140, loss: 35.311808466911316\n",
      "After epoch 4, mini-batch 160, loss: 35.070926547050476\n",
      "After epoch 4, mini-batch 180, loss: 35.0056312084198\n",
      "After epoch 4, mini-batch 200, loss: 34.923569321632385\n",
      "After epoch 4, mini-batch 220, loss: 34.29052770137787\n",
      "After epoch 4, mini-batch 240, loss: 35.34094536304474\n",
      "After epoch 4, mini-batch 260, loss: 35.20228445529938\n",
      "After epoch 4, mini-batch 280, loss: 35.650177121162415\n",
      "After epoch 4, mini-batch 300, loss: 35.24348759651184\n",
      "After epoch 4, mini-batch 320, loss: 34.82835674285889\n",
      "After epoch 4, mini-batch 340, loss: 34.82290256023407\n",
      "After epoch 4, mini-batch 360, loss: 35.34102249145508\n",
      "After epoch 4, mini-batch 380, loss: 34.549307107925415\n",
      "After epoch 4, mini-batch 400, loss: 35.105586528778076\n",
      "After epoch 4, mini-batch 420, loss: 35.218788504600525\n",
      "After epoch 4, mini-batch 440, loss: 35.18256318569183\n",
      "After epoch 4, mini-batch 460, loss: 35.445496678352356\n",
      "After epoch 4, mini-batch 480, loss: 35.0607830286026\n",
      "After epoch 4, mini-batch 500, loss: 35.61223649978638\n",
      "After epoch 4, mini-batch 520, loss: 35.00744891166687\n",
      "After epoch 4, mini-batch 540, loss: 35.07366681098938\n",
      "After epoch 4, mini-batch 560, loss: 35.06315016746521\n",
      "After epoch 4, mini-batch 580, loss: 35.057344913482666\n",
      "After epoch 4, mini-batch 600, loss: 35.03229010105133\n",
      "After epoch 5, mini-batch 20, loss: 34.9017333984375\n",
      "After epoch 5, mini-batch 40, loss: 34.70285105705261\n",
      "After epoch 5, mini-batch 60, loss: 35.092050313949585\n",
      "After epoch 5, mini-batch 80, loss: 35.03632652759552\n",
      "After epoch 5, mini-batch 100, loss: 35.01955032348633\n",
      "After epoch 5, mini-batch 120, loss: 34.830830693244934\n",
      "After epoch 5, mini-batch 140, loss: 34.486053586006165\n",
      "After epoch 5, mini-batch 160, loss: 34.876360058784485\n",
      "After epoch 5, mini-batch 180, loss: 34.98340380191803\n",
      "After epoch 5, mini-batch 200, loss: 34.89596474170685\n",
      "After epoch 5, mini-batch 220, loss: 35.15431571006775\n",
      "After epoch 5, mini-batch 240, loss: 35.097416639328\n",
      "After epoch 5, mini-batch 260, loss: 35.16524016857147\n",
      "After epoch 5, mini-batch 280, loss: 35.01084899902344\n",
      "After epoch 5, mini-batch 300, loss: 34.44403576850891\n",
      "After epoch 5, mini-batch 320, loss: 34.520020842552185\n",
      "After epoch 5, mini-batch 340, loss: 35.10909557342529\n",
      "After epoch 5, mini-batch 360, loss: 34.92541241645813\n",
      "After epoch 5, mini-batch 380, loss: 34.566680908203125\n",
      "After epoch 5, mini-batch 400, loss: 35.10940504074097\n",
      "After epoch 5, mini-batch 420, loss: 34.60699152946472\n",
      "After epoch 5, mini-batch 440, loss: 34.28634166717529\n",
      "After epoch 5, mini-batch 460, loss: 35.50602698326111\n",
      "After epoch 5, mini-batch 480, loss: 35.166550278663635\n",
      "After epoch 5, mini-batch 500, loss: 34.91097438335419\n",
      "After epoch 5, mini-batch 520, loss: 35.15422737598419\n",
      "After epoch 5, mini-batch 540, loss: 34.72659778594971\n",
      "After epoch 5, mini-batch 560, loss: 35.1104781627655\n",
      "After epoch 5, mini-batch 580, loss: 35.06784188747406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After epoch 5, mini-batch 600, loss: 34.587056159973145\n",
      "After epoch 6, mini-batch 20, loss: 34.30345034599304\n",
      "After epoch 6, mini-batch 40, loss: 34.76071286201477\n",
      "After epoch 6, mini-batch 60, loss: 34.65689241886139\n",
      "After epoch 6, mini-batch 80, loss: 34.061206459999084\n",
      "After epoch 6, mini-batch 100, loss: 34.99410426616669\n",
      "After epoch 6, mini-batch 120, loss: 34.232290863990784\n",
      "After epoch 6, mini-batch 140, loss: 34.9503208398819\n",
      "After epoch 6, mini-batch 160, loss: 34.98229217529297\n",
      "After epoch 6, mini-batch 180, loss: 35.259790778160095\n",
      "After epoch 6, mini-batch 200, loss: 34.64217269420624\n",
      "After epoch 6, mini-batch 220, loss: 34.50194466114044\n",
      "After epoch 6, mini-batch 240, loss: 34.60487174987793\n",
      "After epoch 6, mini-batch 260, loss: 34.813679337501526\n",
      "After epoch 6, mini-batch 280, loss: 34.45925176143646\n",
      "After epoch 6, mini-batch 300, loss: 34.7051557302475\n",
      "After epoch 6, mini-batch 320, loss: 34.64745843410492\n",
      "After epoch 6, mini-batch 340, loss: 34.72675621509552\n",
      "After epoch 6, mini-batch 360, loss: 34.16600239276886\n",
      "After epoch 6, mini-batch 380, loss: 34.8045117855072\n",
      "After epoch 6, mini-batch 400, loss: 34.64333689212799\n",
      "After epoch 6, mini-batch 420, loss: 34.9953750371933\n",
      "After epoch 6, mini-batch 440, loss: 34.88473129272461\n",
      "After epoch 6, mini-batch 460, loss: 34.67417013645172\n",
      "After epoch 6, mini-batch 480, loss: 34.72693228721619\n",
      "After epoch 6, mini-batch 500, loss: 35.15737223625183\n",
      "After epoch 6, mini-batch 520, loss: 34.300410985946655\n",
      "After epoch 6, mini-batch 540, loss: 35.097397685050964\n",
      "After epoch 6, mini-batch 560, loss: 34.584131956100464\n",
      "After epoch 6, mini-batch 580, loss: 34.30352556705475\n",
      "After epoch 6, mini-batch 600, loss: 34.83982014656067\n",
      "After epoch 7, mini-batch 20, loss: 34.61614644527435\n",
      "After epoch 7, mini-batch 40, loss: 34.22628653049469\n",
      "After epoch 7, mini-batch 60, loss: 34.61888933181763\n",
      "After epoch 7, mini-batch 80, loss: 34.43572545051575\n",
      "After epoch 7, mini-batch 100, loss: 34.77591037750244\n",
      "After epoch 7, mini-batch 120, loss: 34.21937167644501\n",
      "After epoch 7, mini-batch 140, loss: 35.02143144607544\n",
      "After epoch 7, mini-batch 160, loss: 33.905625343322754\n",
      "After epoch 7, mini-batch 180, loss: 34.50502622127533\n",
      "After epoch 7, mini-batch 200, loss: 34.74535274505615\n",
      "After epoch 7, mini-batch 220, loss: 34.9640429019928\n",
      "After epoch 7, mini-batch 240, loss: 33.98431396484375\n",
      "After epoch 7, mini-batch 260, loss: 34.779712200164795\n",
      "After epoch 7, mini-batch 280, loss: 33.97971725463867\n",
      "After epoch 7, mini-batch 300, loss: 34.4992493391037\n",
      "After epoch 7, mini-batch 320, loss: 34.85428190231323\n",
      "After epoch 7, mini-batch 340, loss: 34.673762917518616\n",
      "After epoch 7, mini-batch 360, loss: 34.83776068687439\n",
      "After epoch 7, mini-batch 380, loss: 34.65144991874695\n",
      "After epoch 7, mini-batch 400, loss: 34.33025670051575\n",
      "After epoch 7, mini-batch 420, loss: 34.04661989212036\n",
      "After epoch 7, mini-batch 440, loss: 34.00009107589722\n",
      "After epoch 7, mini-batch 460, loss: 34.82010471820831\n",
      "After epoch 7, mini-batch 480, loss: 34.247483253479004\n",
      "After epoch 7, mini-batch 500, loss: 34.175771832466125\n",
      "After epoch 7, mini-batch 520, loss: 34.46607482433319\n",
      "After epoch 7, mini-batch 540, loss: 34.92346799373627\n",
      "After epoch 7, mini-batch 560, loss: 34.374178647994995\n",
      "After epoch 7, mini-batch 580, loss: 34.46841073036194\n",
      "After epoch 7, mini-batch 600, loss: 34.23805558681488\n",
      "After epoch 8, mini-batch 20, loss: 34.30500280857086\n",
      "After epoch 8, mini-batch 40, loss: 34.66021692752838\n",
      "After epoch 8, mini-batch 60, loss: 34.22195601463318\n",
      "After epoch 8, mini-batch 80, loss: 34.838343024253845\n",
      "After epoch 8, mini-batch 100, loss: 33.882381439208984\n",
      "After epoch 8, mini-batch 120, loss: 34.41126596927643\n",
      "After epoch 8, mini-batch 140, loss: 34.218916058540344\n",
      "After epoch 8, mini-batch 160, loss: 34.50886058807373\n",
      "After epoch 8, mini-batch 180, loss: 34.285619616508484\n",
      "After epoch 8, mini-batch 200, loss: 34.52328038215637\n",
      "After epoch 8, mini-batch 220, loss: 33.7429039478302\n",
      "After epoch 8, mini-batch 240, loss: 34.79095005989075\n",
      "After epoch 8, mini-batch 260, loss: 34.60093307495117\n",
      "After epoch 8, mini-batch 280, loss: 34.17956614494324\n",
      "After epoch 8, mini-batch 300, loss: 34.417786717414856\n",
      "After epoch 8, mini-batch 320, loss: 33.44327139854431\n",
      "After epoch 8, mini-batch 340, loss: 33.94499921798706\n",
      "After epoch 8, mini-batch 360, loss: 34.54391551017761\n",
      "After epoch 8, mini-batch 380, loss: 33.99379050731659\n",
      "After epoch 8, mini-batch 400, loss: 34.073999762535095\n",
      "After epoch 8, mini-batch 420, loss: 34.0660285949707\n",
      "After epoch 8, mini-batch 440, loss: 34.93958806991577\n",
      "After epoch 8, mini-batch 460, loss: 34.138381242752075\n",
      "After epoch 8, mini-batch 480, loss: 34.33704078197479\n",
      "After epoch 8, mini-batch 500, loss: 34.09410119056702\n",
      "After epoch 8, mini-batch 520, loss: 33.990365386009216\n",
      "After epoch 8, mini-batch 540, loss: 34.64319682121277\n",
      "After epoch 8, mini-batch 560, loss: 34.51266694068909\n",
      "After epoch 8, mini-batch 580, loss: 34.67927145957947\n",
      "After epoch 8, mini-batch 600, loss: 34.02557444572449\n",
      "After epoch 9, mini-batch 20, loss: 34.2868732213974\n",
      "After epoch 9, mini-batch 40, loss: 33.71080219745636\n",
      "After epoch 9, mini-batch 60, loss: 34.194637417793274\n",
      "After epoch 9, mini-batch 80, loss: 33.80871140956879\n",
      "After epoch 9, mini-batch 100, loss: 34.10002648830414\n",
      "After epoch 9, mini-batch 120, loss: 33.59356188774109\n",
      "After epoch 9, mini-batch 140, loss: 34.34141027927399\n",
      "After epoch 9, mini-batch 160, loss: 34.12935411930084\n",
      "After epoch 9, mini-batch 180, loss: 34.37445652484894\n",
      "After epoch 9, mini-batch 200, loss: 33.95145559310913\n",
      "After epoch 9, mini-batch 220, loss: 34.282509326934814\n",
      "After epoch 9, mini-batch 240, loss: 34.050073981285095\n",
      "After epoch 9, mini-batch 260, loss: 34.92315137386322\n",
      "After epoch 9, mini-batch 280, loss: 34.5551438331604\n",
      "After epoch 9, mini-batch 300, loss: 34.494879484176636\n",
      "After epoch 9, mini-batch 320, loss: 33.92211103439331\n",
      "After epoch 9, mini-batch 340, loss: 33.84409046173096\n",
      "After epoch 9, mini-batch 360, loss: 34.86751616001129\n",
      "After epoch 9, mini-batch 380, loss: 34.69911253452301\n",
      "After epoch 9, mini-batch 400, loss: 33.932631969451904\n",
      "After epoch 9, mini-batch 420, loss: 33.984673738479614\n",
      "After epoch 9, mini-batch 440, loss: 34.02126967906952\n",
      "After epoch 9, mini-batch 460, loss: 34.43539500236511\n",
      "After epoch 9, mini-batch 480, loss: 34.05070090293884\n",
      "After epoch 9, mini-batch 500, loss: 33.50381827354431\n",
      "After epoch 9, mini-batch 520, loss: 33.92376267910004\n",
      "After epoch 9, mini-batch 540, loss: 33.78385877609253\n",
      "After epoch 9, mini-batch 560, loss: 33.64807140827179\n",
      "After epoch 9, mini-batch 580, loss: 34.39895713329315\n",
      "After epoch 9, mini-batch 600, loss: 34.47371792793274\n",
      "After epoch 10, mini-batch 20, loss: 33.723944783210754\n",
      "After epoch 10, mini-batch 40, loss: 34.03514504432678\n",
      "After epoch 10, mini-batch 60, loss: 33.53472197055817\n",
      "After epoch 10, mini-batch 80, loss: 34.38687264919281\n",
      "After epoch 10, mini-batch 100, loss: 33.93798804283142\n",
      "After epoch 10, mini-batch 120, loss: 34.0149210691452\n",
      "After epoch 10, mini-batch 140, loss: 33.942280769348145\n",
      "After epoch 10, mini-batch 160, loss: 33.95076537132263\n",
      "After epoch 10, mini-batch 180, loss: 33.56328022480011\n",
      "After epoch 10, mini-batch 200, loss: 33.415173292160034\n",
      "After epoch 10, mini-batch 220, loss: 33.70867955684662\n",
      "After epoch 10, mini-batch 240, loss: 33.65746462345123\n",
      "After epoch 10, mini-batch 260, loss: 33.712398409843445\n",
      "After epoch 10, mini-batch 280, loss: 33.948911905288696\n",
      "After epoch 10, mini-batch 300, loss: 34.06217002868652\n",
      "After epoch 10, mini-batch 320, loss: 33.97880244255066\n",
      "After epoch 10, mini-batch 340, loss: 34.107521295547485\n",
      "After epoch 10, mini-batch 360, loss: 34.304118394851685\n",
      "After epoch 10, mini-batch 380, loss: 34.01803767681122\n",
      "After epoch 10, mini-batch 400, loss: 34.26666867733002\n",
      "After epoch 10, mini-batch 420, loss: 34.42155408859253\n",
      "After epoch 10, mini-batch 440, loss: 34.24889612197876\n",
      "After epoch 10, mini-batch 460, loss: 33.75673711299896\n",
      "After epoch 10, mini-batch 480, loss: 34.72836482524872\n",
      "After epoch 10, mini-batch 500, loss: 33.88405525684357\n",
      "After epoch 10, mini-batch 520, loss: 34.43912875652313\n",
      "After epoch 10, mini-batch 540, loss: 33.45999479293823\n",
      "After epoch 10, mini-batch 560, loss: 33.91276979446411\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After epoch 10, mini-batch 580, loss: 33.62198758125305\n",
      "After epoch 10, mini-batch 600, loss: 34.56807458400726\n"
     ]
    }
   ],
   "source": [
    "total_loss = 0\n",
    "for epoch in range(10):\n",
    "    for i, data in enumerate(train_data_loader, 0):\n",
    "        images, classes = data\n",
    "        images, classes = images.to(device).float(), classes.to(device).long()\n",
    "        #images, classes = images.float(), classes.long()\n",
    "        optimizer.zero_grad()\n",
    "        output = net(images)\n",
    "        #print(output)\n",
    "        \n",
    "        loss = loss_function(output, classes)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item() \n",
    "        if(i % 20 == 19):\n",
    "            print(\"After epoch {}, mini-batch {}, loss: {}\".format(epoch + 1, i + 1, total_loss))\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            total_loss = 0\n",
    "    total_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = FaceDataset('public_test.csv')\n",
    "batch_size = 32\n",
    "test_data_loader = DataLoader(train_data, batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31918149456256284\n",
      "[[ 162    0   79  277  189   43  142]\n",
      " [  14    0   12   37    9    6   20]\n",
      " [  76    0  141  263  203   92  144]\n",
      " [  36    0   67 1153  197   50  118]\n",
      " [  90    0   83  285  368   44  227]\n",
      " [  19    0   58  143   63  347   87]\n",
      " [  60    0   63  306  171   54  460]]\n"
     ]
    }
   ],
   "source": [
    "actual, prediction = [], []\n",
    "for i, data in enumerate(test_data_loader, 0):\n",
    "    images, classes = data\n",
    "    images, classes = images.to(device).float(), classes.to(device).long()\n",
    "    #images, classes = images.float(), classes.long()\n",
    "    actual.extend(classes.squeeze().tolist())\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    output = net(images)\n",
    "    \n",
    "    prediction.extend(torch.argmax(output, dim=1).squeeze().tolist())\n",
    "    #print(output)\n",
    "print(f1_score(actual, prediction, average='macro'))\n",
    "print(confusion_matrix(actual, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 892   98  919 1621 1097  717 1114]\n",
      "[ 457    0  503 2464 1200  636 1198]\n"
     ]
    }
   ],
   "source": [
    "print(np.bincount(np.array(actual)))\n",
    "print(np.bincount(np.array(prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
